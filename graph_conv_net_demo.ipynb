{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph-conv-net-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNskSDHh55Jv2LeLH7taQI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neo-pan/RL_GNN_TSP/blob/master/graph_conv_net_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AHYbdq4KRJ1",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzbUX40eIaW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml6gx2cbIuiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/gdrive/My Drive/NIPS2020\")\n",
        "current_path = os.getcwd()\n",
        "data_root = os.path.join(current_path, \"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdpG9DZ5KZgG",
        "colab_type": "text"
      },
      "source": [
        "## Install Libraries and Extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv6XcARgLJVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install dgl-cu101 memory_profiler line_profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WW_k47DytIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext memory_profiler\n",
        "%load_ext line_profiler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQAi91yT_cDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DegWHbDMiRlK",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries and Set config\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcHkAs08MhG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import dgl\n",
        "import torch\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as dglfn\n",
        "\n",
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy.spatial.distance import cdist\n",
        "# Set logger\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
        "ch = logging.StreamHandler()\n",
        "ch.setFormatter(formatter)\n",
        "ch.setLevel(logging.DEBUG)\n",
        "if not logger.hasHandlers():\n",
        "  logger.addHandler(ch)\n",
        "\n",
        "exp_index = \"s2v_dqn_50_100_cluster_3\"\n",
        "# Tensorboard writer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(f\"runs/{exp_index}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBb2bplniWhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class config():\n",
        "  model_path = os.path.join(current_path, \"model\", exp_index)\n",
        "  batch_size = 128\n",
        "  node_dim = 6\n",
        "  edge_dim = 4\n",
        "  embed_dim = 64\n",
        "  activation = F.relu\n",
        "  max_bp_iter = 4\n",
        "  reg_hidden = 32\n",
        "  w_scale = 0.01\n",
        "  num_env = 1\n",
        "  decay = 0.1\n",
        "  n_step = 1\n",
        "  max_n = 50\n",
        "  min_n = 40\n",
        "  mem_size = 50000\n",
        "  learning_rate = 0.0001\n",
        "  max_iter = 200000\n",
        "  device = torch.device(\"cpu:0\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdLyUD3JKj2r",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXZO82FytCMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dgl.data.utils import load_graphs\n",
        "\n",
        "train_dataset_path = os.path.join(data_root, \"tsp_train_50_100_cluster.bin\")\n",
        "val_dataset_path = os.path.join(data_root, \"tsp_val_50_100_cluster.bin\")\n",
        "assert os.path.exists(train_dataset_path) and os.path.exists(val_dataset_path)\n",
        "\n",
        "train_dataset, _ = load_graphs(train_dataset_path)\n",
        "val_dataset, _ = load_graphs(val_dataset_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl_lHbkqgBnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "# def collate_fn(graphs):\n",
        "#   batched_graph = dgl.batch(graphs)\n",
        "#   return batched_graph\n",
        "\n",
        "# train_set = DataLoader(train_dataset, batch_size = config.batch_size,\n",
        "#             collate_fn = collate_fn)\n",
        "# val_set = DataLoader(val_dataset, batch_size = config.batch_size,\n",
        "#             collate_fn = collate_fn)\n",
        "\n",
        "class GraphPool():\n",
        "  def __init__(self, g_list):\n",
        "    self.graph_pool = g_list\n",
        "    self.size = len(g_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.graph_pool)\n",
        "  \n",
        "  def __getitem__(self, key):\n",
        "    assert key in range(self.size)\n",
        "    return self.graph_pool[key]\n",
        "\n",
        "  def sample(self):\n",
        "    idx = np.random.randint(self.size)\n",
        "    return self[idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02rf7FW8PZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = GraphPool(train_dataset)\n",
        "val_set = GraphPool(val_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_1Ewqs4Gf1",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO6NR3LdTNQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edge_dist_init(edges):\n",
        "  pos1 = edges.src[\"pos\"]\n",
        "  pos2 = edges.dst[\"pos\"]\n",
        "  # Calculate the Euclidean Distance between nodes\n",
        "  dist = torch.sqrt((pos1-pos2).square().sum(dim=1, keepdim=True))\n",
        "\n",
        "  return {\"dist\":dist}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV638Txy4W1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def modify_graph_feature(g, states, actions=None):\n",
        "  assert(g.batch_size==len(states))\n",
        "  if actions:\n",
        "    assert(g.batch_size==len(actions))\n",
        "  # Generate graph for computing\n",
        "  batch_size = g.batch_size\n",
        "  # graph = deepcopy(g)\n",
        "  s, d = g.edges()\n",
        "  graph = dgl.DGLGraph((s,d))\n",
        "\n",
        "  graph.ndata[\"pos\"] = g.ndata[\"pos\"].clone()\n",
        "  graph.readonly(False)\n",
        "\n",
        "  # Calculate cumulated node numbers\n",
        "  cum_num_nodes = np.cumsum([0]+g.batch_num_nodes[:-1])\n",
        "\n",
        "  # Transfer node index to batch index\n",
        "  covered_list = []\n",
        "  for i in range(batch_size):\n",
        "    covered_list.append(np.add(states[i], cum_num_nodes[i]))\n",
        "  all_covered = np.concatenate(covered_list, axis=0)\n",
        "\n",
        "  # First, add edges in tour\n",
        "  tour_list = []\n",
        "  for i, covered in enumerate(covered_list):\n",
        "    if len(covered)==1:\n",
        "      continue\n",
        "    srcs = covered.tolist()\n",
        "    dsts = srcs[1:] + srcs[0:1]\n",
        "    if len(covered)==2:\n",
        "      tour_pair = np.array((srcs, dsts))\n",
        "    else:\n",
        "      tour_pair = np.array((srcs+dsts, dsts+srcs))\n",
        "    tour_list.append(tour_pair)\n",
        "  if tour_list:\n",
        "    all_tour = np.concatenate(tour_list, axis=1)\n",
        "    tour_in_graph = graph.has_edges_between(all_tour[0,:], all_tour[1,:])\n",
        "    tour_to_add = all_tour[:,np.where(tour_in_graph==0)].squeeze()\n",
        "    # logger.debug(f\"tour_to_add:{tour_to_add}\")\n",
        "    graph.add_edges(tour_to_add[0,:], tour_to_add[1,:])\n",
        "  else:\n",
        "    all_tour = np.asarray([[],[]])\n",
        "\n",
        "  # Recalculate distance\n",
        "  graph.apply_edges(edge_dist_init)\n",
        "\n",
        "  # Second, remove edges between selected nodes but not in TSP tour\n",
        "  _edges_src_covered = graph.out_edges(all_covered, form=\"eid\")\n",
        "  _edges_dst_covered = graph.in_edges(all_covered, form=\"eid\")\n",
        "  edges_bothside_covered = np.intersect1d(\n",
        "      _edges_src_covered,\n",
        "      _edges_dst_covered,\n",
        "      assume_unique=True\n",
        "  )\n",
        "  edges_to_reserve = graph.edge_ids(\n",
        "      all_tour[0,:],\n",
        "      all_tour[1,:]\n",
        "  )\n",
        "  edges_to_remove = np.setdiff1d(\n",
        "      edges_bothside_covered,\n",
        "      edges_to_reserve,\n",
        "      assume_unique=True\n",
        "  )\n",
        "  graph.remove_edges(edges_to_remove)\n",
        "  \n",
        "  # Initialize node and edge features\n",
        "  if actions:\n",
        "    graph.init_ndata(\n",
        "        ndata_name=\"action_select\", \n",
        "        shape=(graph.number_of_nodes(), batch_size), \n",
        "        dtype=\"float32\"\n",
        "    )\n",
        "  graph.init_ndata(\n",
        "      ndata_name=\"feat\", \n",
        "      shape=(graph.number_of_nodes(), config.node_dim), \n",
        "      dtype=\"float32\"\n",
        "  )\n",
        "  graph.init_edata(\n",
        "      edata_name=\"feat\",\n",
        "      shape=(graph.number_of_edges(), config.edge_dim),\n",
        "      dtype=\"float32\"\n",
        "  )\n",
        "  if actions:\n",
        "    graph.ndata[\"action_select\"].fill_(0.0)\n",
        "  graph.ndata[\"feat\"].fill_(1.0)\n",
        "  graph.edata[\"feat\"].fill_(0.0)\n",
        "\n",
        "  # Modify graph features wrt states and actions\n",
        "\n",
        "  if actions:\n",
        "    assert len(actions)==cum_num_nodes.shape[0]\n",
        "    actions = np.add(actions, cum_num_nodes)\n",
        "    a_idx = np.array([actions, np.arange(batch_size)])\n",
        "    graph.ndata[\"action_select\"][a_idx[0,:], a_idx[1,:]] = 1.0\n",
        "\n",
        "  start_nodes_covered = np.intersect1d(cum_num_nodes, all_covered, assume_unique=True)\n",
        "\n",
        "  graph.ndata[\"feat\"][cum_num_nodes, 2] = 0.0\n",
        "  graph.ndata[\"feat\"][start_nodes_covered ,3] = 0.0\n",
        "  graph.ndata[\"feat\"][all_covered, 4] = 0.0\n",
        "  \n",
        "  edges_src_covered = graph.out_edges(all_covered, form=\"eid\")\n",
        "  edges_dst_covered = graph.in_edges(all_covered, form=\"eid\")\n",
        "  edegs_oneside_covered = np.setxor1d(\n",
        "    edges_src_covered,\n",
        "    edges_dst_covered,\n",
        "    assume_unique=True\n",
        "  )\n",
        "\n",
        "  graph.edata[\"feat\"][edges_src_covered, 0] = 1.0\n",
        "  graph.edata[\"feat\"][edegs_oneside_covered, 2] = 1.0\n",
        "  graph.edata[\"feat\"][:, 3].fill_(1.0)\n",
        "\n",
        "  graph.ndata[\"feat\"][:, 0:2] = graph.ndata[\"pos\"].clone()\n",
        "  graph.edata[\"feat\"][:, 1:2] = graph.edata[\"dist\"].clone()\n",
        "  \n",
        "  return graph.to(config.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xezGAGvBjZhX",
        "colab": {}
      },
      "source": [
        "def modify_graph_feature_rebuild(g, states, actions=None):\n",
        "  assert(g.batch_size==len(states))\n",
        "  if actions:\n",
        "    assert(g.batch_size==len(actions))\n",
        "  # Generate graph for computing\n",
        "  batch_size = g.batch_size\n",
        "  # graph = deepcopy(g)\n",
        "  s, d = g.edges()\n",
        "  graph = dgl.DGLGraph((s,d))\n",
        "\n",
        "  graph.ndata[\"pos\"] = g.ndata[\"pos\"].clone()\n",
        "  graph.readonly(False)\n",
        "\n",
        "  # Calculate cumulated node numbers\n",
        "  cum_num_nodes = np.cumsum([0]+g.batch_num_nodes[:-1])\n",
        "\n",
        "  # Transfer node index to batch index\n",
        "  covered_list = []\n",
        "  for i in range(batch_size):\n",
        "    covered_list.append(np.add(states[i], cum_num_nodes[i]))\n",
        "  all_covered = np.concatenate(covered_list, axis=0)\n",
        "\n",
        "  # First, add edges in tour\n",
        "  tour_list = []\n",
        "  for i, covered in enumerate(covered_list):\n",
        "    if len(covered)==1:\n",
        "      continue\n",
        "    srcs = covered.tolist()\n",
        "    dsts = srcs[1:] + srcs[0:1]\n",
        "    if len(covered)==2:\n",
        "      tour_pair = np.array((srcs, dsts))\n",
        "    else:\n",
        "      tour_pair = np.array((srcs+dsts, dsts+srcs))\n",
        "    tour_list.append(tour_pair)\n",
        "  if tour_list:\n",
        "    all_tour = np.concatenate(tour_list, axis=1)\n",
        "    tour_in_graph = graph.has_edges_between(all_tour[0,:], all_tour[1,:])\n",
        "    tour_to_add = all_tour[:,np.where(tour_in_graph==0)].squeeze()\n",
        "    # logger.debug(f\"tour_to_add:{tour_to_add}\")\n",
        "    graph.add_edges(tour_to_add[0,:], tour_to_add[1,:])\n",
        "  else:\n",
        "    all_tour = np.asarray([[],[]])\n",
        "\n",
        "  # Recalculate distance\n",
        "  graph.apply_edges(edge_dist_init)\n",
        "\n",
        "  # Second, remove edges between selected nodes but not in TSP tour\n",
        "  _edges_src_covered = graph.out_edges(all_covered, form=\"eid\")\n",
        "  _edges_dst_covered = graph.in_edges(all_covered, form=\"eid\")\n",
        "  edges_bothside_covered = np.intersect1d(\n",
        "      _edges_src_covered,\n",
        "      _edges_dst_covered,\n",
        "      assume_unique=True\n",
        "  )\n",
        "  edges_to_reserve = graph.edge_ids(\n",
        "      all_tour[0,:],\n",
        "      all_tour[1,:]\n",
        "  )\n",
        "  edges_to_remove = np.setdiff1d(\n",
        "      edges_bothside_covered,\n",
        "      edges_to_reserve,\n",
        "      assume_unique=True\n",
        "  )\n",
        "  graph.remove_edges(edges_to_remove)\n",
        "  \n",
        "  # Initialize node and edge features\n",
        "  if actions:\n",
        "    graph.init_ndata(\n",
        "        ndata_name=\"action_select\", \n",
        "        shape=(graph.number_of_nodes(), batch_size), \n",
        "        dtype=\"float32\"\n",
        "    )\n",
        "  graph.init_ndata(\n",
        "      ndata_name=\"feat\", \n",
        "      shape=(graph.number_of_nodes(), config.node_dim), \n",
        "      dtype=\"float32\"\n",
        "  )\n",
        "  graph.init_edata(\n",
        "      edata_name=\"feat\",\n",
        "      shape=(graph.number_of_edges(), config.edge_dim),\n",
        "      dtype=\"float32\"\n",
        "  )\n",
        "  if actions:\n",
        "    graph.ndata[\"action_select\"].fill_(0.0)\n",
        "  graph.ndata[\"feat\"].fill_(1.0)\n",
        "  graph.edata[\"feat\"].fill_(0.0)\n",
        "\n",
        "  # Modify graph features wrt states and actions\n",
        "\n",
        "  if actions:\n",
        "    assert len(actions)==cum_num_nodes.shape[0]\n",
        "    actions = np.add(actions, cum_num_nodes)\n",
        "    a_idx = np.array([actions, np.arange(batch_size)])\n",
        "    graph.ndata[\"action_select\"][a_idx[0,:], a_idx[1,:]] = 1.0\n",
        "\n",
        "  start_nodes_covered = np.intersect1d(cum_num_nodes, all_covered, assume_unique=True)\n",
        "\n",
        "  graph.ndata[\"feat\"][cum_num_nodes, 2] = 0.0\n",
        "  graph.ndata[\"feat\"][start_nodes_covered ,3] = 0.0\n",
        "  graph.ndata[\"feat\"][all_covered, 4] = 0.0\n",
        "  \n",
        "  edges_src_covered = graph.out_edges(all_covered, form=\"eid\")\n",
        "  edges_dst_covered = graph.in_edges(all_covered, form=\"eid\")\n",
        "  edegs_oneside_covered = np.setxor1d(\n",
        "    edges_src_covered,\n",
        "    edges_dst_covered,\n",
        "    assume_unique=True\n",
        "  )\n",
        "\n",
        "  graph.edata[\"feat\"][edges_src_covered, 0] = 1.0\n",
        "  graph.edata[\"feat\"][edegs_oneside_covered, 2] = 1.0\n",
        "  graph.edata[\"feat\"][:, 3].fill_(1.0)\n",
        "\n",
        "  graph.ndata[\"feat\"][:, 0:2] = graph.ndata[\"pos\"].clone()\n",
        "  graph.edata[\"feat\"][:, 1:2] = graph.edata[\"dist\"].clone()\n",
        "  \n",
        "  return graph.to(config.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xla3ABiLgSy0",
        "colab_type": "text"
      },
      "source": [
        "## Build Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vHS7pWWgWh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class S2VLayer(nn.Module):\n",
        "  def __init__(self, embed_dim, activation):\n",
        "    super().__init__()\n",
        "    self.activation = activation\n",
        "    self.node_linear_conv = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "    self.trans_node_1 = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "    self.trans_node_2 = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "\n",
        "  def edge_msg(self, edges):\n",
        "    msg = torch.add(edges.src[\"node_msg\"], edges.data[\"edge_init\"])\n",
        "    msg = self.activation(msg)\n",
        "    return {\"edge_msg\": msg}\n",
        "\n",
        "  def forward(self, g, cur_node_embed):\n",
        "    with g.local_scope():\n",
        "      # Node embedding linear transformation\n",
        "      node_msg = self.node_linear_conv(cur_node_embed)\n",
        "      # logger.debug(f\"n_node: {g.number_of_nodes()}\")\n",
        "      \n",
        "      g.ndata[\"node_msg\"] = node_msg\n",
        "      # Calculate edge message\n",
        "      g.apply_edges(self.edge_msg)\n",
        "      # Message Passing\n",
        "      g.update_all(\n",
        "          message_func=dglfn.copy_e(e=\"edge_msg\", out=\"msg\"),\n",
        "          reduce_func=dglfn.sum(msg=\"msg\", out=\"node_reduce\")\n",
        "      )\n",
        "      # Linear transformation and element-wise add\n",
        "      node_linear = torch.add(\n",
        "          self.trans_node_1(g.ndata[\"node_reduce\"]),\n",
        "          self.trans_node_2(cur_node_embed)\n",
        "      )\n",
        "      return self.activation(node_linear)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXQwxGOnmkq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class S2VTSPNet(nn.Module):\n",
        "  def __init__(self, node_dim, edge_dim, embed_dim,\n",
        "            activation, max_bp_iter, reg_hidden):\n",
        "    super().__init__()\n",
        "    self.activation = activation\n",
        "    self.max_bp_iter = max_bp_iter\n",
        "    self.node_to_latent = nn.Linear(node_dim, embed_dim, bias=False)\n",
        "    self.edge_to_latent = nn.Linear(edge_dim, embed_dim, bias=False)\n",
        "    self.s2v_layer = S2VLayer(embed_dim, self.activation)\n",
        "\n",
        "    if(reg_hidden>0):\n",
        "      self.reg_layers = nn.Sequential(\n",
        "          nn.Linear(embed_dim, reg_hidden, bias=False),\n",
        "          nn.Linear(reg_hidden, 1, bias=False)\n",
        "      )\n",
        "    else:\n",
        "      self.reg_layers = nn.Linear(embed_dim, 1, bias=False)\n",
        "\n",
        "  def _forward(self, g):\n",
        "    # Feature to latent\n",
        "    node_init = self.node_to_latent(g.ndata[\"feat\"])\n",
        "    edge_init = self.edge_to_latent(g.edata[\"feat\"])\n",
        "    g.edata[\"edge_init\"] = edge_init\n",
        "    cur_node_embed = self.activation(node_init)\n",
        "    # Graph message passing\n",
        "    for i in range(self.max_bp_iter):\n",
        "      cur_node_embed = self.s2v_layer(g, cur_node_embed)\n",
        "\n",
        "    return cur_node_embed\n",
        "\n",
        "  def forward(self, g):\n",
        "    cur_node_embed = self._forward(g)\n",
        "    # Action embed\n",
        "    action_embed = torch.matmul(\n",
        "        g.ndata[\"action_select\"].t(), cur_node_embed\n",
        "    )\n",
        "    # Predicted q value given a\n",
        "    q_pred = action_embed\n",
        "    for layer in self.reg_layers:\n",
        "      q_pred = layer(q_pred)\n",
        "    return q_pred\n",
        "\n",
        "  def predict_all(self, g):\n",
        "    cur_node_embed = self._forward(g)\n",
        "    # Q value for all actions\n",
        "    q_on_all = cur_node_embed\n",
        "    for layer in self.reg_layers:\n",
        "      q_on_all = layer(q_on_all)\n",
        "    return q_on_all\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oq2GjY4oxV5b",
        "colab": {}
      },
      "source": [
        "class DQNTSPModel(nn.Module):\n",
        "  def __init__(self, node_dim, edge_dim, embed_dim,\n",
        "            activation, max_bp_iter, reg_hidden):\n",
        "    super().__init__()\n",
        "    self.eval_net = S2VTSPNet(node_dim, edge_dim, embed_dim,\n",
        "            activation, max_bp_iter, reg_hidden)\n",
        "    self.target_net = S2VTSPNet(node_dim, edge_dim, embed_dim,\n",
        "            activation, max_bp_iter, reg_hidden)\n",
        "    \n",
        "    self.target_net.requires_grad_(False)\n",
        "\n",
        "  def forward(self, graph):\n",
        "    q_pred = self.eval_net(graph)\n",
        "    del graph\n",
        "\n",
        "    return q_pred\n",
        "\n",
        "  def predict(self, graph):\n",
        "    with torch.no_grad():\n",
        "      q_on_all = self.target_net.predict_all(graph)\n",
        "      q_on_all = torch.where(\n",
        "          graph.ndata[\"feat\"][:,4].unsqueeze(-1)==0.0,\n",
        "          torch.tensor(float(\"-inf\")).to(config.device),\n",
        "          q_on_all\n",
        "      )\n",
        "      del graph\n",
        "\n",
        "      return q_on_all\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.target_net.load_state_dict(\n",
        "        self.eval_net.state_dict()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU83gdQjbLIF",
        "colab_type": "text"
      },
      "source": [
        "## TSP Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n59A9gebQHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TSPEnv():\n",
        "  def __init__(self, norm):\n",
        "    self.norm = norm\n",
        "    self.graph = None # Graph used in GNN\n",
        "    self.graph_size = 0\n",
        "    self.dist_matrix = None\n",
        "    self.state_seq = []\n",
        "    self.act_seq = []\n",
        "    self.action_list = []\n",
        "    self.reward_seq = []\n",
        "    self.sum_rewards = []\n",
        "    self.partial_set = set()\n",
        "    self.trajectory_len = 0\n",
        "  \n",
        "  def clear(self):\n",
        "    self.dist_matrix = None\n",
        "    self.state_seq.clear()\n",
        "    self.act_seq.clear()\n",
        "    self.action_list.clear()\n",
        "    self.reward_seq.clear()\n",
        "    self.sum_rewards.clear()\n",
        "    self.partial_set.clear()\n",
        "    self.action_list.append(0)\n",
        "    self.partial_set.add(0)\n",
        "    self.trajectory_len = 0\n",
        "\n",
        "  def reset(self, graph):\n",
        "    self.clear()\n",
        "    self.graph = graph\n",
        "    self.graph_size = graph.number_of_nodes()\n",
        "    self.dist_matrix = cdist(graph.ndata[\"pos\"], graph.ndata[\"pos\"])\n",
        "\n",
        "  @property\n",
        "  def has_graph(self):\n",
        "    return self.graph is not None\n",
        "\n",
        "  def _add_node(self, node):\n",
        "    # Insert helper function\n",
        "    # logger.debug(f\"add new node id: {node}\")\n",
        "\n",
        "    srcs = self.action_list\n",
        "    dsts = srcs[1:] + srcs[0:1]\n",
        "    \n",
        "    srcs = np.array(srcs)\n",
        "    dsts = np.array(dsts)\n",
        "\n",
        "    # Find insert position that minimize the additional cost\n",
        "    # logger.debug(f\"num_nodes:{self.graph.number_of_nodes()}, num_edges:{self.graph.number_of_edges()}\")\n",
        "    # src_dst_node = np.vstack(np.broadcast_arrays(\n",
        "    #     src,\n",
        "    #     dst,\n",
        "    #     node\n",
        "    # ))\n",
        "    cost_list = self.dist_matrix[srcs, node] \\\n",
        "      + self.dist_matrix[dsts, node] \\\n",
        "      - self.dist_matrix[srcs, dsts]\n",
        "    assert(cost_list.ndim==1)\n",
        "    pos = np.argmin(cost_list)\n",
        "    cost = cost_list[pos]\n",
        "    if cost < 0:\n",
        "      logger.warning(f\"cost less than zero\\n \\\n",
        "      src:{src_dst_node[0,pos]}, \\\n",
        "      dst:{src_dst_node[1,pos]}, \\\n",
        "      node:{src_dst_node[2,pos]}\")\n",
        "      cost = 0\n",
        "    # for i, (src, dst) in enumerate(tour_pair):\n",
        "    #   cost = self.dist_matrix[node, src] \\\n",
        "    #     + self.dist_matrix[node, dst] \\\n",
        "    #     - self.dist_matrix[src, dst]\n",
        "    #   if(cost < cur_dist):\n",
        "    #     cur_dist = cost\n",
        "    #     pos = i\n",
        "    #     if (cur_dist<0):\n",
        "    #       logger.warning(f\"distance less than 0\\n \\\n",
        "    #         node:{node}, src:{src}, dst:{dst}, cost:{cost}\\n \\\n",
        "    #         {self.dist_matrix[node, src]}\\n \\\n",
        "    #         {self.dist_matrix[node, dst]}\\n \\\n",
        "    #         {self.dist_matrix[src, dst]}\"\n",
        "    #       )\n",
        "    #       cur_dist=0\n",
        "\n",
        "    assert(pos>=0)\n",
        "    self.action_list.insert(pos+1, node)\n",
        "    self.partial_set.add(node)\n",
        "\n",
        "    return cost / self.norm\n",
        "\n",
        "  def step(self, a):\n",
        "    assert(self.has_graph)\n",
        "    assert(not self.is_terminal)\n",
        "    assert(a not in self.partial_set)\n",
        "    assert(a > 0)\n",
        "    assert(a < self.graph_size), f\"a:{a}, num_nodes:{self.graph_size}\"\n",
        "    \n",
        "    self.state_seq.append(self.action_list.copy())\n",
        "    self.act_seq.append(a)\n",
        "\n",
        "    r_t = self._add_node(a)\n",
        "\n",
        "    self.reward_seq.append(r_t)\n",
        "    self.sum_rewards.append(r_t)\n",
        "    self.trajectory_len += 1\n",
        "\n",
        "    assert(\n",
        "        len(self.action_list)\n",
        "        ==len(self.partial_set)\n",
        "        ==self.trajectory_len+1\n",
        "    )\n",
        "    assert(\n",
        "        len(self.state_seq)\n",
        "        ==len(self.act_seq)\n",
        "        ==len(self.reward_seq)\n",
        "        ==len(self.sum_rewards)\n",
        "        ==self.trajectory_len\n",
        "    )\n",
        "\n",
        "    return r_t\n",
        "\n",
        "  def random_action(self):\n",
        "    assert(self.has_graph)\n",
        "    avail_list= []\n",
        "    for i in range(self.graph_size):\n",
        "      if i not in self.partial_set:\n",
        "        avail_list.append(i)\n",
        "    idx = np.random.randint(len(avail_list))\n",
        "    return avail_list[idx]\n",
        "\n",
        "  @property\n",
        "  def is_terminal(self):\n",
        "    assert(self.has_graph)\n",
        "    return (self.trajectory_len+1)==self.graph_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85DuJG8i_av",
        "colab_type": "text"
      },
      "source": [
        "## Replay Memory and Simulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "falDLCYs-xeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sample():\n",
        "  def __init__(self, batch_size):\n",
        "    self.size = batch_size\n",
        "    self.g_list = []\n",
        "    self.s_list = []\n",
        "    self.a_list = []\n",
        "    self.r_list = []\n",
        "    self.s_prime_list = []\n",
        "    self.t_list = []\n",
        "\n",
        "class ReplayMemory():\n",
        "  def __init__(self, mem_size):\n",
        "    self.capacity = mem_size\n",
        "    self._memory = [None for i in range(mem_size)]\n",
        "    self.size = 0\n",
        "    self.idx = 0\n",
        "\n",
        "  def store(self, experience):\n",
        "    # experience=(g, s, a, r, s', t)\n",
        "    assert(len(experience)==6)\n",
        "    self._memory[self.idx] = deepcopy(experience)\n",
        "    self.idx += 1\n",
        "    self.idx = self.idx % self.capacity\n",
        "    self.size = max(self.size, self.idx)\n",
        "\n",
        "  def add_env(self, env):\n",
        "    assert(env.is_terminal)\n",
        "    num_steps = env.trajectory_len\n",
        "    for i in range(num_steps-2,-1,-1):\n",
        "      # Cauculate cumsum reward\n",
        "      env.sum_rewards[i] = env.sum_rewards[i+1] + env.sum_rewards[i]\n",
        "    for i in range(num_steps):\n",
        "      if i+config.n_step >= num_steps:\n",
        "        r = env.sum_rewards[i]\n",
        "        s_prime = env.action_list\n",
        "        t = True\n",
        "      else:\n",
        "        r = env.sum_rewards[i] - env.sum_rewards[i+config.n_step]\n",
        "        s_prime = env.state_seq[i+config.n_step]\n",
        "        t = False\n",
        "      # experience=(g, s, a, r, s', t)\n",
        "      self.store((env.graph, env.state_seq[i], env.act_seq[i], r, s_prime, t))\n",
        "\n",
        "  def clear(self):\n",
        "    self.idx = 0\n",
        "    self.size = 0\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    sample = Sample(batch_size)\n",
        "    for i in range(batch_size):\n",
        "      idx = np.random.randint(0, self.size)\n",
        "      g, s, a, r, s_prime, t = self._memory[idx]\n",
        "      sample.g_list.append(g)\n",
        "      sample.s_list.append(s)\n",
        "      sample.a_list.append(a)\n",
        "      sample.r_list.append(r)\n",
        "      sample.s_prime_list.append(s_prime)\n",
        "      sample.t_list.append(t)\n",
        "\n",
        "    return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb6ccheJjDv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Simulator():\n",
        "  def __init__(self, num_env, replay_mem):\n",
        "    self.num_env = num_env\n",
        "    self.env_list = [TSPEnv(config.max_n) for _ in range(num_env)]\n",
        "    self.state_list = [None for _ in range(num_env)]\n",
        "    self.replay_mem = replay_mem\n",
        "\n",
        "  def reset(self):\n",
        "    self.env_list = [TSPEnv(config.max_n) for _ in range(self.num_env)]\n",
        "    self.state_list = [None for _ in range(self.num_env)]\n",
        "    \n",
        "  def run(self, num_seqs, eps, model, graph_pool):\n",
        "    assert(eps>=0.0 and eps<=1.0)\n",
        "    n = 0\n",
        "    while n<num_seqs:\n",
        "      for i in range(self.num_env):\n",
        "        if (not self.env_list[i].has_graph) or (self.env_list[i].is_terminal):\n",
        "          if (self.env_list[i].has_graph) and (self.env_list[i].is_terminal):\n",
        "            n+=1\n",
        "            self.replay_mem.add_env(self.env_list[i])\n",
        "          # Reset env graph\n",
        "          graph = graph_pool.sample()\n",
        "          self.env_list[i].reset(graph)\n",
        "          self.state_list[i] = self.env_list[i].action_list\n",
        "      if n>=num_seqs:\n",
        "        break\n",
        "\n",
        "      random = np.random.uniform(low=0.0, high=1.0) < eps\n",
        "      if random:\n",
        "        for i in range(self.num_env):\n",
        "          a = self.env_list[i].random_action()\n",
        "          self.env_list[i].step(a)\n",
        "      else:\n",
        "        g_batch = dgl.batch([env.graph for env in self.env_list])\n",
        "        cum_num_nodes = np.cumsum([0] + g_batch.batch_num_nodes)\n",
        "        q_pred = model.predict(g_batch, self.state_list)\n",
        "        for i in range(self.num_env):\n",
        "          a = torch.argmax(q_pred[cum_num_nodes[i]:cum_num_nodes[i+1]])\n",
        "          self.env_list[i].step(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVTDuWN5ZpfA",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXzWdH41aSOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(config.model_path):\n",
        "  os.mkdir(config.model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja_Qo0FMnL5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(graph_pool, model):\n",
        "  batch_size = graph_pool.size\n",
        "  g_batch = dgl.batch(graph_pool.graph_pool)\n",
        "  cum_num_nodes = np.cumsum([0] + g_batch.batch_num_nodes)\n",
        "  env_list = [TSPEnv(config.max_n) for i in range(batch_size)]\n",
        "  s_list = []\n",
        "  r_list = [0 for i in range(batch_size)]\n",
        "  t_list = [False for i in range(batch_size)]\n",
        "  for i in range(batch_size):\n",
        "    env_list[i].reset(graph_pool[i])\n",
        "    s_list.append(env_list[i].action_list)\n",
        "  \n",
        "  while False in t_list:\n",
        "    # logger.debug(r_list)\n",
        "    graph = modify_graph_feature(g_batch, s_list)\n",
        "    q_list = model.predict(graph)\n",
        "    # logger.debug(q_list.shape)\n",
        "    for i in range(batch_size):\n",
        "      if not env_list[i].is_terminal:\n",
        "        a = torch.argmax(q_list[cum_num_nodes[i]:cum_num_nodes[i+1]]).cpu()\n",
        "        # logger.debug(f\"action of env {i}: {a}\")\n",
        "        r = env_list[i].step(a)\n",
        "        # logger.debug(f\"reward of env {i}: {r}\")\n",
        "        r_list[i] += r * config.max_n\n",
        "      else:\n",
        "        if not t_list[i]:\n",
        "          t_list[i] = True\n",
        "  del env_list\n",
        "  del g_batch\n",
        "  return np.sum(r_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybax_Zp9E96j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DQNTSPModel(\n",
        "    config.node_dim,\n",
        "    config.edge_dim,\n",
        "    config.embed_dim,\n",
        "    config.activation,\n",
        "    config.max_bp_iter,\n",
        "    config.reg_hidden\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Ns2y-W3Ufg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(config.device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMfdcBPRwrMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_memory = ReplayMemory(config.mem_size)\n",
        "simulator = Simulator(config.num_env, replay_memory)\n",
        "test_env = TSPEnv(config.max_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmQcsfETj2gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replay Memory Startup\n",
        "simulator.reset()\n",
        "for i in tqdm(range(10)):\n",
        "  simulator.run(100, 1, model, train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZicBDttRYcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_memory.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K8Pfihq5Cn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = config.learning_rate\n",
        "eps_start = 1.0\n",
        "eps_end = 1.0\n",
        "eps_step = 10000.0\n",
        "current_iter = 0\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.Adam(model.eval_net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M-Cb-urptem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_load_path = \"/gdrive/My Drive/NIPS2020/model/s2v_dqn_50_100_cluster_2/nrange_40_50_iter_34400.pth\"\n",
        "\n",
        "if os.path.exists(model_load_path):\n",
        "  checkpoint = torch.load(model_load_path)\n",
        "  current_iter = checkpoint['iter']+1\n",
        "  model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "  optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPV8EYfau14x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for iter in tqdm(range(current_iter, config.max_iter+1)):\n",
        "# def prun_test(\n",
        "#     iter=1,\n",
        "#     lr=lr,\n",
        "#     eps_start=eps_start,\n",
        "#     eps_end=eps_end,\n",
        "#     eps_step=eps_step,\n",
        "#     loss_fn=loss_fn,\n",
        "#     optimizer=optimizer,):\n",
        "  lr = optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "\n",
        "  # Get samples from replay memory\n",
        "  sample = replay_memory.sample(config.batch_size)\n",
        "  g_batch = dgl.batch(sample.g_list)\n",
        "  batch_size = g_batch.batch_size\n",
        "  cum_num_nodes = np.cumsum([0] + g_batch.batch_num_nodes)\n",
        "  graph_predict = modify_graph_feature(g_batch, sample.s_prime_list)\n",
        "  graph_forward = modify_graph_feature(g_batch, sample.s_list, sample.a_list)\n",
        "\n",
        "  # Target Network\n",
        "  q_pred = model.predict(graph_predict)\n",
        "  q_rhs = np.zeros((sample.size, 1))\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    if not sample.t_list[i]:\n",
        "      q_rhs[i] = config.decay \\\n",
        "        * torch.max(q_pred[cum_num_nodes[i]:cum_num_nodes[i+1]]).cpu()\n",
        "\n",
        "  q_target = np.add(\n",
        "      q_rhs,\n",
        "      np.asarray(sample.r_list)[...,np.newaxis]\n",
        "  ).astype(np.float32)\n",
        "\n",
        "  q_target = torch.from_numpy(q_target).to(config.device)\n",
        "\n",
        "  q_eval = model.forward(graph_forward)\n",
        "\n",
        "  loss = loss_fn(q_eval, q_target)\n",
        "  # tensorboard log\n",
        "  writer.add_scalar(\"loss\", loss, global_step=iter)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  eps = eps_end + max(0., (eps_start - eps_end) * (eps_step - iter) / eps_step)\n",
        "  if iter % 10 == 0:\n",
        "    simulator.run(10, eps, model, train_set)\n",
        "  if iter % 100 == 0:\n",
        "    tour_len = validate(val_set, model)\n",
        "    writer.add_scalar(\"val_tour_len\", tour_len, global_step=iter)\n",
        "    model_path = os.path.join(\n",
        "      config.model_path,\n",
        "      f\"nrange_{config.min_n}_{config.max_n}_iter_{iter}.pth\"\n",
        "    )\n",
        "\n",
        "    tqdm.write(\n",
        "      f\"\\riter: {iter}, lr: {lr}, eps: {eps},\\\n",
        "  average tour length: {tour_len/len(val_set)},\\\n",
        "  loss: {loss},\\\n",
        "  model saved: {model_path}\",\n",
        "      end=''\n",
        "    )\n",
        "\n",
        "    torch.save({\n",
        "        'iter': iter,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "      },\n",
        "      model_path\n",
        "    )\n",
        "    gc.collect()\n",
        "  if iter % 1000 == 0:\n",
        "    model.update_target_network()\n",
        "    lr = lr * 0.95\n",
        "    for p_group in optimizer.param_groups:\n",
        "      p_group[\"lr\"] = lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZh95JOYx8Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate(val_set, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36m0UcVRLPMh",
        "colab_type": "text"
      },
      "source": [
        "## Debug Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjq-_alsuLcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%lprun -f prun_test -f modify_graph_feature -f validate prun_test(iter=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3OZVXDX6u2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samplep = replay_memory.sample(128)\n",
        "g_batch = dgl.batch(samplep.g_list)\n",
        "g_sample = samplep.g_list[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCgEMgicowHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.draw(g_sample.to_networkx(), pos={i:g_sample.ndata[\"pos\"][i] for i in range(g_sample.number_of_nodes())})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX1nl_HD04mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 1\n",
        "%aimport mprun_demo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DThY8XXYoLQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mprun_demo\n",
        "from mprun_demo import prun_test, model, validate, simulator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nW2g60evgIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tracemalloc\n",
        "\n",
        "tracemalloc.start(25)\n",
        "\n",
        "for i in tqdm(range(5000)):\n",
        "  mgraph = modify_graph_feature(dgl.batch(samplep.g_list),samplep.s_list,samplep.a_list)\n",
        "\n",
        "snapshot = tracemalloc.take_snapshot()\n",
        "top_stats = snapshot.statistics('lineno')\n",
        "\n",
        "print(\"[ Top 10 ]\")\n",
        "for stat in top_stats[:10]:\n",
        "    print(stat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiLdZqjp-5S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for stat in top_stats[0:10]:\n",
        "  print(f\"------Block------\")\n",
        "  for line in stat.traceback.format():\n",
        "    print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrlMN1ZksWsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in tracemalloc.get_object_traceback(graph):\n",
        "  print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKP9gsaB5Snz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in tqdm(range(5000)):\n",
        "%lprun -f modify_graph_feature mgraph = modify_graph_feature(dgl.batch(samplep.g_list),samplep.s_list,samplep.a_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWnsNUO6xiJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mprun -f prun_test -f model.forward -f model.predict -f validate -f simulator.run prun_test(iters=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2rHjEgqi8xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_x = np.arange(3)\n",
        "pos_y = np.arange(3)\n",
        "pos = np.meshgrid(pos_x, pos_y)\n",
        "pos = np.concatenate((pos[0].flatten()[..., np.newaxis], pos[1].flatten()[..., np.newaxis]), axis=1)\n",
        "gdemo = dgl.transform.knn_graph(torch.tensor(pos), 8)\n",
        "# nx.draw(gdemo.to_networkx())\n",
        "gdemo = dgl.transform.remove_self_loop(gdemo)\n",
        "# nx.draw(gdemo.to_networkx())\n",
        "gdemo = dgl.transform.to_bidirected(gdemo)\n",
        "\n",
        "gdemo.ndata[\"pos\"] = pos.astype(np.float32)\n",
        "gdemo.apply_edges(edge_dist_init)\n",
        "gnet = gdemo.to_networkx(edge_attrs=[\"dist\"])\n",
        "dmatrix = nx.floyd_warshall_numpy(gnet, weight=\"dist\")\n",
        "\n",
        "nx.draw(gdemo.to_networkx(), pos={i : pos[i] for i in range(9)})\n",
        "gdemo.number_of_edges()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpQ0N39t0_uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = np.arange(5).tolist()\n",
        "states = [0,1,2,5,4,3]\n",
        "states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4JXBzJkSPZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actions = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82IaC1RP00-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nx_test(g):\n",
        "  graph = deepcopy(g.to_networkx())\n",
        "\n",
        "def rebuild_test(g):\n",
        "  s, d = g.edges()\n",
        "  graph = dgl.DGLGraph((s,d))\n",
        "\n",
        "%timeit nx_test(g_batch)\n",
        "%timeit rebuild_test(g_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyfWpzux1Kzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUilr-N8fUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracemalloc.get_traced_memory()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9eJj9rJxMKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyAKMxLPxFif",
        "colab_type": "text"
      },
      "source": [
        "## Result Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mnl2d38WY97p",
        "colab": {}
      },
      "source": [
        "r, s_list, a_list = validate(val_set, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7-7uWNditZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_tsp(p, x_coord, W, W_val, W_target, title=\"default\"):\n",
        "    \"\"\"\n",
        "    Helper function to plot TSP tours.\n",
        "    \n",
        "    Args:\n",
        "        p: Matplotlib figure/subplot\n",
        "        x_coord: Coordinates of nodes\n",
        "        W: Edge adjacency matrix\n",
        "        W_val: Edge values (distance) matrix\n",
        "        W_target: One-hot matrix with 1s on groundtruth/predicted edges\n",
        "        title: Title of figure/subplot\n",
        "    \n",
        "    Returns:\n",
        "        p: Updated figure/subplot\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def _edges_to_node_pairs(W):\n",
        "        \"\"\"Helper function to convert edge matrix into pairs of adjacent nodes.\n",
        "        \"\"\"\n",
        "        pairs = []\n",
        "        for r in range(len(W)):\n",
        "            for c in range(len(W)):\n",
        "                if W[r][c] == 1:\n",
        "                    pairs.append((r, c))\n",
        "        return pairs\n",
        "    \n",
        "    G = nx.from_numpy_matrix(W_val)\n",
        "    pos = dict(zip(range(len(x_coord)), x_coord.tolist()))\n",
        "    adj_pairs = _edges_to_node_pairs(W)\n",
        "    target_pairs = _edges_to_node_pairs(W_target)\n",
        "    colors = ['g'] + ['b'] * (len(x_coord) - 1)  # Green for 0th node, blue for others\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=50)\n",
        "    nx.draw_networkx_edges(G, pos, edgelist=adj_pairs, alpha=0.3, width=0.5)\n",
        "    nx.draw_networkx_edges(G, pos, edgelist=target_pairs, alpha=1, width=1, edge_color='r')\n",
        "    p.set_title(title)\n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Yb-HwVpYLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_index = 1\n",
        "\n",
        "for i in range(len(s_list[graph_index])-1):\n",
        "  a = s_list[graph_index][i]\n",
        "\n",
        "  tour = list(zip(a[:], a[1:]+a[0:1]))\n",
        "  w_target = np.zeros((50,50))\n",
        "  for p in tour:\n",
        "    w_target[p[0], p[1]]=1\n",
        "\n",
        "  fig = plt.subplot(111)\n",
        "  plot_tsp(\n",
        "      fig,\n",
        "      val_set[graph_index].ndata[\"pos\"],\n",
        "      val_set[graph_index].adjacency_matrix_scipy(return_edge_ids=False).todense().tolist(),\n",
        "      cdist(val_set[graph_index].ndata[\"pos\"],val_set[graph_index].ndata[\"pos\"]),\n",
        "      w_target,\n",
        "      title=f\"step {i}\"\n",
        "  )\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY9pVShMkaTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from termcolor import colored\n",
        "\n",
        "for i, state in enumerate(s_list[graph_index]):\n",
        "  if i==0:\n",
        "    for i,n in enumerate(state):\n",
        "      print(n, end=\" \")\n",
        "      if (i+1)%20==0:\n",
        "        print(\"\")\n",
        "  else:\n",
        "    action = a_list[graph_index][i-1].tolist()\n",
        "    for i,n in enumerate(state):\n",
        "      if not n in action:\n",
        "        print(n, end=\" \")\n",
        "      else:\n",
        "        print(colored(n, color=\"red\"), end=\" \")\n",
        "      if (i+1)%20==0:\n",
        "        print(\"\")\n",
        "  print(\"\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}